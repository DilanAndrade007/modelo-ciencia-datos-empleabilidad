## Proyecto: ExtracciÃ³n de Ofertas de Empleo para AnÃ¡lisis de Habilidades Blandas

---

### ğŸ¯ Objetivo

Este sistema permite la **extracciÃ³n automatizada, trazable y escalable** de descripciones de ofertas laborales desde mÃºltiples plataformas (iniciando con Jooble), clasificadas por **carrera universitaria** y preparadas para anÃ¡lisis posteriores de habilidades blandas mediante procesamiento de lenguaje natural (NLP).

---

### ğŸ“ Estructura del Proyecto

```
soft_skills_scraper/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ platforms.yml                # ConfiguraciÃ³n de plataformas, API keys y tÃ©rminos por carrera
â”‚
â”œâ”€â”€ extractors/
â”‚   â”œâ”€â”€ jooble_api.py               # MÃ³dulo especÃ­fico para extracciÃ³n desde Jooble API
â”‚   â””â”€â”€ rapidapi_api.py             # MÃ³dulo especÃ­fico para extracciÃ³n desde RapidApi API
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ file_manager.py             # Funciones auxiliares para manejo de logs, corpus y carpetas
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ jooble_log.json             # Registro de estado por tÃ©rmino de bÃºsqueda y fecha
â”‚   â””â”€â”€ rapidapi_log.json           # Registro de estado por tÃ©rmino de bÃºsqueda y fecha
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ outputs/
â”‚       â””â”€â”€ jooble/
â”‚           â”œâ”€â”€ <Carrera>/
â”‚           â”‚   â”œâ”€â”€ jooble__<tÃ©rmino>__<YYYY-MM-DD>.csv
â”‚           â”‚   â””â”€â”€ corpus_unido/
â”‚           â”‚       â””â”€â”€ jooble__<Carrera>__<YYYY-MM-DD>__merged.csv
â”‚           rapidapi/
â”‚           â”œâ”€â”€ <Carrera>/
â”‚           â”‚   â”œâ”€â”€ rapidapi__<tÃ©rmino>__<YYYY-MM-DD>.csv
â”‚           â”‚   â””â”€â”€ corpus_unido/
â”‚           â”‚       â””â”€â”€ rapidapi__<Carrera>__<YYYY-MM-DD>__merged.csv
â”‚           todas_las_plataformas/
â”‚           â””â”€â”€ <Carrera>/
â”‚               â”œâ”€â”€ jooble__<Carrera>__<YYYY-MM-DD>__merged.csv
â”‚               â””â”€â”€ rapidapi__<Carrera>__<YYYY-MM-DD>__merged.csv
â”‚                   
â”‚
â”‚
â””â”€â”€ README.md
```
  pip install selenium beautifulsoup4 pandas 

---

### âš™ï¸ Â¿QuÃ© hace este sistema?

1. Lee tÃ©rminos de bÃºsqueda por carrera desde `config/platforms.yml`.
2. Extrae resultados desde la API de Jooble, con paginaciÃ³n completa.
3. Verifica si el scraping ya se ejecutÃ³ hoy y pregunta si deseas repetirlo.
4. Reanuda automÃ¡ticamente si una extracciÃ³n fue interrumpida.
5. Evita duplicados mediante `job_id` inteligente.
6. Guarda los resultados organizados por plataforma y carrera.
7. Une automÃ¡ticamente todos los `.csv` diarios por carrera en un Ãºnico corpus consolidado en `corpus_unido/`.
8. Mantiene un registro histÃ³rico por plataforma, tÃ©rmino y fecha.

---

### ğŸ§ª Campos estÃ¡ndar del corpus generado

Cada fila del corpus `.csv` contiene:

| Campo                  | DescripciÃ³n                                       |
| ---------------------- | ------------------------------------------------- |
| `job_id`               | Hash Ãºnico (tÃ­tulo + empresa + ubicaciÃ³n + fecha) |
| `source`               | Plataforma de origen (ej. `jooble`)               |
| `job_title`            | TÃ­tulo del empleo                                 |
| `company`              | Nombre de la empresa                              |
| `location`             | UbicaciÃ³n geogrÃ¡fica                              |
| `description`          | Texto completo de la oferta                       |
| `skills`               | Skils recuperadas de la oferta                    |
| `careers_required`     | Carrera requerida en la oferta                    |
| `date_posted`          | Fecha de publicaciÃ³n                              |
| `url`                  | Enlace original a la oferta                       |
| `career_tag`           | VacÃ­o (clasificaciÃ³n futura)                      |
| `soft_skills_detected` | VacÃ­o (para anÃ¡lisis posterior)                   |
| `extraction_date`      | Fecha en que se realizÃ³ la extracciÃ³n             |

---

### ğŸ§­ EjecuciÃ³n

```bash
python main.py
```

El sistema:

* RecorrerÃ¡ todas las carreras y tÃ©rminos definidos para cada plataforma activa.
* DetectarÃ¡ si ya hiciste scraping hoy y te preguntarÃ¡ si deseas repetirlo.
* GuardarÃ¡ y unificarÃ¡ los resultados por carrera en `corpus_unido/`.

---

### ğŸ§  Control de extracciÃ³n

El sistema mantiene un log estructurado por plataforma en `logs/<plataforma>_log.json`, por ejemplo:

```json
{
  "administraciÃ³n": {
    "last_extraction_date": "2025-06-11",
    "total_offers_extracted": 86,
    "last_page_extracted": 5
  }
}

---

### ğŸ› ï¸ ConfiguraciÃ³n del archivo `platforms.yml`

```yaml
jooble:
  enabled: true
  api_key: "TU_API_KEY"
  carreras:
    AdministraciÃ³n de Empresas:
      - administraciÃ³n
      - administrador
    IngenierÃ­a QuÃ­mica:
      - IngenierÃ­a QuÃ­mica
```

* Cada carrera puede tener mÃºltiples tÃ©rminos de bÃºsqueda.
* Todas las consultas se agrupan por carrera en la carpeta correspondiente.

---

### ğŸ—‚ï¸ ConsolidaciÃ³n de corpus entre plataformas

AdemÃ¡s de guardar los corpus diarios por plataforma y carrera, el sistema genera una **copia adicional de cada corpus diario unificado** en una carpeta comÃºn para facilitar el anÃ¡lisis multifuente:

```
data/outputs/todas_las_plataformas/<Carrera>/jooble__<Carrera>__YYYY-MM-DD__merged.csv
```

---

### ğŸ“¦ Corpus acumulado por carrera

El sistema tambiÃ©n crea automÃ¡ticamente un archivo **acumulado por carrera**, que incluye todos los corpus diarios histÃ³ricos (de todas las fechas) ya unificados:

```
data/outputs/jooble/<Carrera>/corpus_unido/corpus__<Carrera>__acumulado.csv
```

Este archivo se actualiza en cada ejecuciÃ³n y elimina duplicados por `job_id`.

---

### Cambios

Se busca integrear coresignal como api para poder extraer datos desde linkedin
---